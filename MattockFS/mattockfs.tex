\chapter{MattockFS}
In this appendix we describe the functionality and design of a new user-space file-system. MattockFS is meant to be a successor to the user space file-system named CarvFS that was released by the Dutch National Police to act as an annotation based pseudo file-system aimed at facilitating zero-storage carving to the OCFA forensic framework. While CarvFS was retrofitted to work with OCFA, with MattockFS we aim to create a new user-space file-system modeled partially after CarvFS that should act as the potential foundation of new message passing oriented forensic framework. We envision that MattockFS, together with a shared key/value store,a serialization library and OCFA-Anycast like message bus technology could form the foundation for an envisioned future \emph{Mattock} forensic framework. The aim is to implement as much as is logical and sensible of the main aspects of disk-cache optimization techniques into this user space file-system. This should include facilities for querying throttling relevant information, facilities for keeping track of \emph{active} CarvPaths, facilities for marking expected read-access patterns for a given CarvPath and for marking a CarvPath as no longer needed. Also it shall include facilities for opportunistic hashing. Finally, while in OCFA, the concept of a growing archive was implemented by allowing a data-generating module access to the raw data-file underlying the file-system, in MattockFS we shall opt to implement this trough a file-system layer. This file-system should have the potential of becoming one of the foundational stones for the construction of a next generation open source message-passing concurrency based computer forensics framework. We shall refer to this envisioned framework that will need to interact closely with MattockFS as the Mattock framework or i\emph{Mattock} for short.
\section{FUSE: File-system in user-space}
In Linux, a file-system will normally reside in kernel-space. Sometimes statically as part of the main kernel, and often as a kernel loadable module. While from a performance point of view, kernel-space file-systems are preferable, writing software to run in kernel space is quite challenging and comes with many pitfalls. Most software libraries that are available in user-space are unavailable in kernel-space, and even much of the standard OS API functionality is not accessible in the same familiar and convenient access patterns. next to these concerns, there are security implications to the concept of running a large body of programming logic at the level of a trusted kernel module. As an alternative to kernel level file-systems, the Linux kernel comes with a special file-system loadable module and an accompanying user-space library that together are aptly named FUSE. FUSE is an almost-acronym that stands for Filesystem in User-space. The kernel module communicates with the library and together they allow the creation of a regular user-space process that performs the task of being a file-system. MattockFS, like CarvFS before it, aims to be such a user-space file-system. 
\section{MattockFS functionality}
MattockFS aims to become a successor to CarvFS, implementing the facilities needed for doing zero-storage (also  named "in place") file carving within the context of a computer forensic framework as CarvFS did, but also implementing a range of functionalities that aid in reducing the page-cache-miss-rate for the Mattock framework that it facilitates. Next to this, MattockFS shall implement some facilities relating to mutable data access that should contribute to the overall robustness of the framework and the integrity of the forensic process.
\subsection{The concept of concurrent pseudo-batches}
While processing of data in a forensic frameworks is something quite dynamic, when seen from MattockFS we can look at it as a large number of concurrent pseudo-batches. Each batch works on one specific piece of data as designated by one specific CarvPath. A batch consists of a set of operations on the data, each operation done by one specific framework module. A set of operations that has a beginning and an end. As such, from the point of view of the file-system, the framework and the file-system cooperate in completing pseudo-batches that are designated with the same CarvPath that also designates the data that the batch works upon. This concept of pseudo-batches is an important concept in each of the sub-responsibilities of MattockFS.
\subsection{Adding data to the archives}
In OCFA the concept of a \emph{growing archive} was introduced. The idea of a growing archive is that a large raw data file is made available through a filesystem like CarvFS of MattockFS, and that data entry processes (called kickstarts in OCFA) and data derivation processes (called dissectors in OCFA) are allowed to \emph{grow} the underlying raw data file that the file-system runs on top of. One major drawback of this approach was that the growing archive would need to be writable to each and every data producing kickstart or dissector (or as in OCFA, each and every module). Each module, or tool invoked by a module, then has the power not only to add new data to the archive, but also to potentially corrupt the existing archive. Given the reality of both anti-forensics and of software bugs in many data processing tools that might be used from within the context of a forensic framework, this approach is undesirable from a robustness and data integrity point of view. To alleviate this concern, MattockFS will implement an add-only interface for allowing Mattock modules to enter or derive data without being able to modify any of the data that was entered into the filesystem at an earlier point. Not only for data that was entered by other modules but even to the extend of not allowing mutable state to exist in any data that was fully submitted by the same module itself. MattockFS shall ensure both exclusivity of access during creation and immutability of data after it has first been fully submitted by its creator.
\subsection{Annotation based data access}
As in CarvFS, the core of the functionality of MattockFS is centered around the concept of annotation based access to data. CarvFS defined a convention for annotations named CarvPath that MattockFS will be adopting. This convention can be summarized as:
\begin{itemize}
\item CarvPath annotations can be nested like directories separated by a directory separation character as defined for the particular OS. For Linux that character is '/'. In a multi layered CarvPath, each level designates a CarvPath relative to the directory level above it. MattockFS (like CarvFS before it) will \emph{flatten} all multi-level CarvPath annotations by representing second level CarvPath entities as symbolic links to their first level \emph{flattened} representation.
\item Each CarvPath annotation comes in two forms. The \emph{directory} form that consists of just the CarvPath without a file extension, and the \emph{raw} form that is denoted using the same CarvPath, but postfixed with the \emph{.crv} file name extension.
\item A CarvPath can denote a fragmented entity within its parent. In such a case, the character '\_' is used as a separator between the fragments.
\item A \emph{normal} fragment consists of two decimal numbers separated by a \emph{'+'} sign. The first represents the offset within the parent entity. The second number denotes the size of the fragment.
\item A fragment can be defined as being \emph{sparse}. This means there is no actual data there, and if the data is read, all zeroes will be returned. A \emph{sparse} fragment is denoted as a capital \emph{'S'} followed by the size of the sparse fragment in decimal form.
\item A CarvPath may end up being longer than the OS file-system allows a directory level to be. For that reason a CarvPath annotation for a really long very fragmented CarvPath may be replaced with a digest of the CarvPath. Such a digest/CarvPath mapping will need to be stored in order to allow usage of the digest for accessing the underlying data. Note that this aspect of CarvPath annotations creates a challenge for distributed usage of CarvPath annotations. We shall discuss these concerns further down below.  
\end{itemize}
\subsection{Framework usage vs interactive usage}
The initial version of MattockFS prioritizes usage from within a framework context over interactive usage. As such performance in the interactive usage of MattockFS could be sub-optimal. It is recognized that in a real operational environment the interactive usage and framework usage will often occur simultaneous and may thus intervene with each-other. This is left as a subject for further study that falls outside of the context of this research project. We shall act as if interactive usage of MattockFS will be rare. We shall focus on MattockFS usage from within the context of pseudo-batches. Optimization of non-pseudo-batch usage is considered as an important subject, yet a subject that is not within scope for this research project.
\subsection{Page usage control, monitoring \& release}
MattockFS, when looking at it from a distance, is nothing more than a fancy wrapper for an open file handle to a huge (growing) raw archive-file. MattockFS will try to, using the \emph{fadvice} API as described in the previous appendix, in order to communicate with the kernel about keeping or no longer keeping pieces of the huge raw archive-file in the page-cache. So when should MattockFS mark a certain section of our archive to be kept or released from the page-cache? Its a quite delicate process involving reference counting, pseudo-batch marking and the opening and closing of pseudo files within the file-system. A brief outline of a simple strategy:
\begin{itemize}
\item When a batch is marked, all space indicated by the batch has a \emph{WILLNEED} reference counter incremented.
\item When a batch is unmarked, all space indicated by the batch has a \emph{WILLNEED} reference counter decremented.
\item When a pseudo file is opened, all space indicated by the pseudo file  has a \emph{NORMAL}  reference count incremented.
\item When a pseudo file is closed, all space indicated by the pseudo file has a \emph{NORMAL} reference count decremented.
\item Whenever needed, fadvice is invoked for an area resulting from reference counter values. The last \emph{advice} for any given region needs to be;
\begin{itemize}
\item \(WILLNEED == 0 ; NORMAL == 0 \Rightarrow FADV\_DONTNEED \)
\item \(WILLNEED == 0 ; NORMAL > 0 \Rightarrow FADV\_NORMAL \)
\item \(WILLNEED > 0 \Rightarrow FADV\_DONTNEED \)
\end{itemize} 
\end{itemize}
MattockFS will be keeping track of these reference counters, and as such will be able to keep track of what it has asked the kernel to keep in page cache. This information will proof useful for our throttling control later on.
\subsection{Throttling control}
While MattockFS itself does not concern itself with throttling, it is in a unique position to provide data providers within the Mattock framework with information that should proof useful then implementing effective throttling strategies. The throttling related bookkeeping in MattockFS consists of three distinct parts:
\begin{itemize}
\item The file-system provides information on the total amount of file fragment that are marked as FADV\_DONTNEED or FADV\_NORMAL.
\item As MattockFS handles read operations, and as the kernel provides the \emph{mincore} API call for checking if a page to be read resides in the page cache, MattockFS provides information as to the recent success rates with regards to page cache hits.
\item A data producing module may issue a \emph{what if} query regarding a CarvPath. This query will return the expected growth in page-cache demand resulting from consecutive marking of the CarvPath as a pseudo-batch.
\end{itemize}
The combination of these three sources of information from MattockFS should allow the modules in the framework to delay marking new pseudo-batches until old pseudo-batches have completed, possibly by throttling using the messaging subsystem.
\subsection{Opportunistic hashing}
Next to the whole \emph{fadvice} and throttling part, the concept of pseudo-batches also comes into play when implementing our opportunistic hashing. Whenever the combination of the two reference counters goes from zero to one, an opportunistic hashing context is initiated and an offset is initiated at zero. Now whenever, during the lifetime of the batch, a piece of data is read that roughly connects to the offset location, than an opportunistic hashing operation that hashes part of the data and forwards the hashing offset is attempted. If the connection isn't seamless but close, \emph{mincore} is used to check if the intermediate space happens to already be in page cache. Further, the pages directly following the requested data are also checked using the \emph{mincore} operation. Whatever chunk of in-core data can move the hashing offset forward will be used to do so.
\subsection{Choice of algorithm}
If we discard the interesting and important efforts in the fields of partial and fuzzy hashing and focus on full-entity hashing, there are four main ways how hashes are used in computer forensic processing.
\begin{itemize}
\item Check against known good. This includes abandoning further processing for for example Windows OS system files.
\item Check against known bad. This includes marking for example known child pornography image files.
\item Check against \emph{seen before}. This can keep a forensic framework from for example unzipping a large archive that is found in many places for every place where it was found.
\item Applying set-theory to groups of files from different sources within a single investigation. This includes things like allowing an investigator to select all office documents unique to the intersection of office files found on the systems of two suspects.
\end{itemize} 
For the first two purposes, compatibility of the hashing algorithms used in the known file hashes data set with the hashing algorithm used by the framework is important. For the other two purposes there exists only one algorithm; the one used by the framework. It is with the first two types of usage that we run into an issue witch choosing a hashing algorithm for MattockFS. The problem is that data-set producers seem to be behind the curve with regards to secure hashing. Many known-file data-set providers only provide SHA1 hashes. According to NIST, SHA1 is deprecated for the \emph{generation} of secure hashes (as was MD5 before it). Even NIST though still distributes their \emph{NSRL} known-file hash data-set with (next to SHA256 hashes) SHA1 hashes.  The apparent reason for this is that the secure SHA256 hash has very poor performance when used in software. As use of hashes in computer forensics involves the hashing of large amounts of data, and as access speeds to that data are increasing as the use of solid state disks in CF setups gains more traction, the poor performance of the more secure SHA256 becomes a serious performance consideration. There are several alternative hashing algorithms that combine a strong and secure hash with a decent or good performance on a software platform. Most notably two (non-winning) candidates for SHA-3: SKEIN and BLAKE. Those however come with a lack of compatibility with our dataset providers. Finally, a successor to BLAKE, BLAKE2bp comes in forms optimized to take advantage of 64 bit multi core systems. We must acknowledge though that SKEIN and the original BLAKE, as being part of the SHA-3 competition will likely have been more scrutinized than BLAKE2, so our trust may be slightly less in that algorithm. A short overview :
\begin{table}[]
\centering
\begin{tabular}{llllr}
Algorithm & Secure & Trusted & Compatible & Speed compared to SHA1 \\ \hline
SHA1 & NO & YES & YES & 100\% \\
SHA256 & YES & YES & YES & 30\% \\
SKEIN & YES & YES & NO & 75\% \\
BLAKE2b & YES & NO* & NO & 135\% \\
BLAKE2bp & YES & NO* & NO & 420\% \\
\end{tabular}
\end{table}
When we look at the numbers above, we can conclude that combining SHA1 with the multi-core 64 bit optimized BLAKE2bp algorithm will give us at least the security of SHA256 combined with the compatibility of SHA1 at a performance hit of only 20\% when compared to only using SHA1. We pose that a final version of MattockFS shall support the following modes and algorithms for the user to choose between:
\begin{itemize}
\item SHA1 only (100\% speed; compatible/insecure)
\item BLAKE2bp only (420\% speed; incompatible/secure)
\item Dual hashing (80\% speed; compatible/secure)
\end{itemize} 
Within the context of the initial version of MattockFS that falls within the scope of this research project, we shall implement only one of these modes.
\subsection{Distributed access concerns}
Given that MattockFS at its basis is an overlay file-system, much of the distributed access can be addressed by storing the raw archive file on an underlying file-system with distributed access. This could be something like a StorNext File System (SNFS) that allows multiple servers fiber channel access to the same data, or something like a simple NFS share. This part falls outside of the scope of concern for MattockFS.
There is however one essential distribution concern not directly related to distributed file-systems: The digest representation of long CarvPath annotations. We shall make sure that MattockFS allows for a loosely coupled link to a key/value store system that is usable in a distributed setting. A system such as \emph{Redis} would appear like a good match for such functionality. 
\section{Basic directory structure}
MattockFS uses the following base directory structure:
\begin{itemize}
\item \emph{data.crv} : A pseudo file representing the entire archive.
\item \emph{data/} : The top level for CarvPath access to the data.
\item \emph{mattockfs.info} : Empty pseudo file for file-system level interaction.
\item \emph{newdata/} : Pseudo directory for entering new data.
\end{itemize}
The data.crv file and data/ directory work in exactly the same way that CarvFS did. Nested CarvPath annotations redirect to first level flattened CarvPath annotations that are than accessible as pseudo files. What is different about the data directory is that the pseudo files inside of it allow for a close interaction of the framework using MattockFS with the throttling, page-cache management and opportunistic hashing logic inside of MattockFS and indirectly with the page-cache control functionality within the Linux Kernel. This interaction is done through the use of an extended attribute based control mechanism. Some interactions don't make sense on a per-CarvPath basis and are done against the MattockFS file-system as a whole. For that reason the pseudo file mattockfs.info acts as a front for MattockFS as a whole. This file comes with its own distinct extended attributes. Finally the directory newdata. This directory allow each distinct process accessing MattockFS to create a new pseudo file what's content is to be appended to the growing archive underlying the file-system. 
\section{CarvPath level attribute based control and info}
At the level of individual CarvPath annotations, extended attributes are to be used to interact with MattockFS. We define the following attributes:
\begin{itemize}
\item \emph{batch} : Settable boolean variable denoting if framework or script will access this CarvPath again with an other module soon. If \emph{true} MattockFS will attempt to have the kernel keep the accessed part of this CarvPath in the page-cache until set to \emph{false}. Setting \emph{batch} to \emph{true} will also initiate opportunistic hashing for the CarvPath.
\item \emph{advise}: Read only value denoting the currently set \emph{advice} value as set for the CarvPath.
\begin{itemize}
\item \emph{normal}: Set to POSIX\_FADV\_NORMAL
\item \emph{willneed}: Set to  POSIX\_FADV\_WILLNEED
\item \emph{dontneed}: Nothing set or explicitly set to POSIX\_FADV\_DONTNEED.
\item \emph{ambiguous}: Different parts of this CarvPath have a different status.
\end{itemize} 
\item \emph{incore} This attribute represents two distinct operations. When read, this variable will return a boolean indicating if the CarvPath is available in full from the page-cache. When set to \emph{true}, the CarvPath is set to POSIX\_FADV\_WILLNEED and the \emph{readahead} system API is invoked to read any uncached file data into the page-cache. This write operation will only be honored when invoked while a batch is active for this CarvPath. 
\item \emph{refcount} : This read-only attribute returns two semicolon separated integers denoting the number minimum and maximum reference count for fragments within the CarvPath indicated. If an ISO image containing a mailbox containing an individual mail is processed and all three levels are still active, requesting \emph{refcount} for the ISO image should yield \emph{1;3}, for the mailbox: {2,3} and for the individual mail \emph{3;3}. This functionality is meant for debug purposes only. 
\item \emph{throttle} : This read-only attribute returns two semicolon separated numbers indicating the price (page-cache wise) of submitting a specific CarvPath. The two numbers returned are:
\begin{itemize} 
\item The \emph{current} size of the total archive fragments for what \emph{fadvice} was invoked with a last value other than POSIX\_FADV\_DONTNEED. 
\item The total size of the additional fragments that will be marked if a batch is actively marked or the CarvPath is opened as a file. 
\end{itemize}
The result of this information is to be used for throttling purposes by the Mattock library.   
\item \emph{hash} : If fully hashed, this read-only attribute contains the 64 character hexadecimal representation of either the BLAKE2bp hash, or the SHA1 hash of the data. If both sha1 and BLAKE2 are enabled, the value here will be the BLAKE2bp hash. Until the CarvPath is fully hashed, this attribute will not be available yet.
\item \emph{sha1} :If fully hashed, this read-only attribute contains the 40 character hexadecimal representation of the 20 byte SHA-1 hash of the data. While use of SHA-1 is believed soon to become deprecated, within computer forensics systems the use of SHA-1 based, accepted and widely used data sets still depend on SHA-1. If MattockFS has SHA1 disabled than this attribute will not be available. Until the CarvPath is fully hashed, this attribute will not be available yet.
\item \emph{offset} : If not fully hashed yet, this read-only attribute contains the offset of the first byte in the file not sequentially read yet by the opportunistic hashing engine. If a hash is required from the file-system, a user can simply read the remainder of the file stating at the indicated offset. After the whole remainder of the file has been processed, the \emph{b2b} or/and \emph{sha1} attribute will be set appropriately.
\end{itemize}
\section{File-System level attribute based control}
While most interaction between MattockFS and the framework using it, will go through CarvPath annotated pseudo files, a limited set of information exists only at a file-system level. This is done using the extended attributes of the pseudo file \emph{mattockfs.info}. The following attributes are defined:
\begin{itemize}
\item \emph{size} : Read only attribute denoting the size of the \emph{fadviced} file fragments that have not \emph{yet} been set to DONTNEED.
\item \emph{normalsize} : Read only attribute denoting the size of just the \emph{fadviced} file fragments that have been explicitly marked as NORMAL. This excludes the space advised at WILLNEED level.
\item \emph{pcwillneed} : Read only attribute denoting the size of the \emph{fadviced} file fragments that have been explicitly marked as WILLNEED. This excludes the space advised at NORMAL level.
\item \emph{batchcount} : Read only attribute denoting the current number of active batch markings for CarvPath annotations.
\item \emph{filecount} : Read only attribute denoting the current number of open pseudo files for CarvPath annotations.
\item \emph{hashingcount} : Read only attribute denoting the current number of incomplete non abandoned opportunistic hashing state objects.
\item \emph{algorithms} : Read only attribute that returns the names of the hashing algorithms that have currently been configured.
\end{itemize}
\section{Creating new files}
The way to create new content in MattockFS is the creation of a specially named file in the \emph{newdata} directory. The file needs to have a CarvPath like name starting with '0+' followed by the size that needs to be allocated for this file. The file should have one of two extensions. If the file is to, once submitted, be implicitly marked as a pseudo batch, than the file extension '.bat' should be used. This should be default in-framework behavior. If however no implicit  batch context is required, than '.new' should be the file extension. A kickstart operation or derivation of data should take the following steps:
\begin{itemize}
\item Determine the size of the target file and calculate a proper file name. For example \emph{newdata/0+43246.bat} .
\item Open the file for writing.
\item Fill the non-sparse parts of the data, staying within the bounds of the claimed space.
\item Close the file.
\item After closing the file is now represented as a symbolic link. Read and dereference the symlink.
\item Delete the file.
\end{itemize} 
Note that the newdata directory is process id bound. The file is writable only to the process that created it and the symlink must be dereferenced as symlink and unlinked by that same process. While this may be inconvenient in combination with bash scripts, this setup assures the robustness of the system and immutability properties of the created data. Future versions of MattockFS may add supports for initially unknown file-size data submission. For the context of this research project however this feature falls outside of the scope.
